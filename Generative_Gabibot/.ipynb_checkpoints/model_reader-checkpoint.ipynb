{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Load trained models and load pickles\n",
    "model = load_model(\"model_500e_line2kl\")\n",
    "encoder_model = load_model('encoder_model_500e_2kl')\n",
    "decoder_model = load_model('decoder_model_500e_2kl')\n",
    "\n",
    "with open('input_word2idx_500e_2kl.pickle', 'rb') as f:\n",
    "    input_word2idx = pickle.load(f)\n",
    "\n",
    "with open('target_word2idx_500e_2kl.pickle', 'rb') as f:\n",
    "    target_word2idx = pickle.load(f)\n",
    "\n",
    "input_idx2word = dict([(idx, word) for word, idx in input_word2idx.items()])\n",
    "target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
    "\n",
    "num_encoder_tokens = len(input_idx2word)\n",
    "num_decoder_tokens = len(target_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " god doesnt exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the hidden cost of reddit who is this in one of reason is more than one who crashed my privilege'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run and write, the bot will reply with a comment\n",
    "input_text = input()\n",
    "input_seq = []\n",
    "input_wids = []\n",
    "max_encoder_seq_length = 30\n",
    "max_decoder_seq_length = 20\n",
    "\n",
    "for word in nltk.word_tokenize(input_text.lower()):\n",
    "    idx = 1\n",
    "    if word in input_word2idx:\n",
    "        idx = input_word2idx[word]\n",
    "    input_wids.append(idx)\n",
    "    \n",
    "input_seq.append(input_wids)\n",
    "input_seq = pad_sequences(input_seq, max_encoder_seq_length)\n",
    "states_value = encoder_model.predict(input_seq)\n",
    "target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "target_seq[0, 0, target_word2idx['START']] = 1\n",
    "target_text = ''\n",
    "target_text_len = 0\n",
    "terminated = False\n",
    "\n",
    "while not terminated:\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "    sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
    "    sample_word = target_idx2word[sample_token_idx]\n",
    "    target_text_len += 1\n",
    "\n",
    "    if sample_word != 'START' and sample_word != 'END':\n",
    "        target_text += ' ' + sample_word\n",
    "\n",
    "    if sample_word == 'END' or target_text_len >= max_decoder_seq_length:\n",
    "        terminated = True\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sample_token_idx] = 1\n",
    "\n",
    "    states_value = [h, c]\n",
    "    \n",
    "\n",
    "target_text.strip().replace('UNK', '')\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
