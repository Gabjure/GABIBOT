{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:32.756405Z",
     "start_time": "2020-05-31T16:55:32.748652Z"
    }
   },
   "outputs": [],
   "source": [
    "#Basic libraries to import:\n",
    "import numpy as np  #used for scientific computing - not used in this case but you never know when you might need it\n",
    "import pandas as pd #for data manipulation and analysis - used to upload de DS we are working with.\n",
    "\n",
    "#NLP\n",
    "import nltk # Natural Language Toolkit, platform for building Python programs to work with human language data.\n",
    "\n",
    "#nltk.download('punkt') # tokenizer that divides a text into a list of sentences\n",
    "\n",
    "from collections import Counter #container that keeps track of how many times equivalent values are added.\n",
    "\n",
    "from keras.models import Model, load_model   #groups layers into an object with training and inference features\n",
    "\n",
    "from keras.layers import Dense, Input, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:34.824428Z",
     "start_time": "2020-05-31T16:55:33.627964Z"
    }
   },
   "outputs": [],
   "source": [
    "# set default parameters\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 200\n",
    "HIDDEN_UNITS = 100 #256\n",
    "MAX_INPUT_SEQ_LENGTH = 20\n",
    "MAX_TARGET_SEQ_LENGTH = 20\n",
    "MAX_VOCAB_SIZE = 20000 #10-20k  https://coursefinders.com/blog/es/5669/espanol-cuantas-palabras-se-necesitan-para-hablar-con-fluidez-un-idioma\n",
    "\n",
    "input_counter = Counter()\n",
    "target_counter = Counter()\n",
    "\n",
    "# read the data\n",
    "\n",
    "df = pd.read_csv('SARC_DS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:37.000620Z",
     "start_time": "2020-05-31T16:55:36.970527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answer_1</th>\n",
       "      <th>Answer_2</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've been searching for the answer for this fo...</td>\n",
       "      <td>Religion must have the answer</td>\n",
       "      <td>It's obviously tracks from a giant water tract...</td>\n",
       "      <td>I've been searching for the answer for this fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
       "      <td>Wow...he smoked pot...oh lord hes such a horri...</td>\n",
       "      <td>Wow, his girlfriend is uhm... Ah fuck it, he's...</td>\n",
       "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Utah wants to create a database to track the i...</td>\n",
       "      <td>I think the government should track every morm...</td>\n",
       "      <td>Another idea from the party that wants to get ...</td>\n",
       "      <td>Utah wants to create a database to track the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Six Million Dead Jews of World War ONE!</td>\n",
       "      <td>Oh right, *both* wars were just jewish conspir...</td>\n",
       "      <td>i know this seems strange but, what if he was ...</td>\n",
       "      <td>The Six Million Dead Jews of World War ONE! Oh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WSJ begins the Jeb Bush campaign for 2016</td>\n",
       "      <td>Good luck with that.</td>\n",
       "      <td>time to get that shack in montana.</td>\n",
       "      <td>WSJ begins the Jeb Bush campaign for 2016 Good...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  I've been searching for the answer for this fo...   \n",
       "1  Michael Phelps Apologizes For \"Regrettable\" Be...   \n",
       "2  Utah wants to create a database to track the i...   \n",
       "3        The Six Million Dead Jews of World War ONE!   \n",
       "4          WSJ begins the Jeb Bush campaign for 2016   \n",
       "\n",
       "                                            Answer_1  \\\n",
       "0                      Religion must have the answer   \n",
       "1  Wow...he smoked pot...oh lord hes such a horri...   \n",
       "2  I think the government should track every morm...   \n",
       "3  Oh right, *both* wars were just jewish conspir...   \n",
       "4                               Good luck with that.   \n",
       "\n",
       "                                            Answer_2  \\\n",
       "0  It's obviously tracks from a giant water tract...   \n",
       "1  Wow, his girlfriend is uhm... Ah fuck it, he's...   \n",
       "2  Another idea from the party that wants to get ...   \n",
       "3  i know this seems strange but, what if he was ...   \n",
       "4                 time to get that shack in montana.   \n",
       "\n",
       "                                                 all  \n",
       "0  I've been searching for the answer for this fo...  \n",
       "1  Michael Phelps Apologizes For \"Regrettable\" Be...  \n",
       "2  Utah wants to create a database to track the i...  \n",
       "3  The Six Million Dead Jews of World War ONE! Oh...  \n",
       "4  WSJ begins the Jeb Bush campaign for 2016 Good...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:37.344792Z",
     "start_time": "2020-05-31T16:55:37.308646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've been searching for the answer for this for some time, but I still can't find any answer... Can anyone please explain to me what this is? Religion must have the answer It's obviously tracks from a giant water tractor, farming for giant arctic sea prawn!\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['all'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:38.823919Z",
     "start_time": "2020-05-31T16:55:38.773604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 128540 entries, 0 to 128539\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   Questions  128540 non-null  object\n",
      " 1   Answer_1   128540 non-null  object\n",
      " 2   Answer_2   128540 non-null  object\n",
      " 3   all        128540 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:43.431361Z",
     "start_time": "2020-05-31T16:55:43.426500Z"
    }
   },
   "outputs": [],
   "source": [
    "lines = df['all'][:100]\n",
    "input_texts = []\n",
    "target_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:44.043255Z",
     "start_time": "2020-05-31T16:55:44.036134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)\n",
    "# len(input_texts)\n",
    "# len(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:44.939496Z",
     "start_time": "2020-05-31T16:55:44.865985Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_words = []\n",
    "\n",
    "for line in lines:\n",
    "\n",
    "    next_words = [w.lower() for w in nltk.word_tokenize(line) if w.isalpha()]\n",
    "    \n",
    "\n",
    "    if len(next_words) > MAX_TARGET_SEQ_LENGTH:\n",
    "        next_words = next_words[0:MAX_TARGET_SEQ_LENGTH]\n",
    "\n",
    "    if len(prev_words) > 0:\n",
    "        input_texts.append(prev_words)\n",
    "        for w in prev_words:\n",
    "            input_counter[w] += 1\n",
    "        target_words = next_words[:]\n",
    "        target_words.insert(0, 'START')\n",
    "        target_words.append('END')\n",
    "        for w in target_words:\n",
    "            target_counter[w] += 1\n",
    "        target_texts.append(target_words)\n",
    "\n",
    "    prev_words = next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:45.473991Z",
     "start_time": "2020-05-31T16:55:45.466298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:46.439595Z",
     "start_time": "2020-05-31T16:55:46.419909Z"
    }
   },
   "outputs": [],
   "source": [
    "# encode the data\n",
    "input_word2idx = dict()\n",
    "target_word2idx = dict()\n",
    "for idx, word in enumerate(input_counter.most_common(MAX_VOCAB_SIZE)):\n",
    "    input_word2idx[word[0]] = idx + 2\n",
    "for idx, word in enumerate(target_counter.most_common(MAX_VOCAB_SIZE)):\n",
    "    target_word2idx[word[0]] = idx + 1\n",
    "\n",
    "input_word2idx['PAD'] = 0\n",
    "input_word2idx['UNK'] = 1\n",
    "target_word2idx['UNK'] = 0\n",
    "\n",
    "input_idx2word = dict([(idx, word) for word, idx in input_word2idx.items()])\n",
    "target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
    "\n",
    "num_encoder_tokens = len(input_idx2word)\n",
    "num_decoder_tokens = len(target_idx2word)\n",
    "\n",
    "\n",
    "encoder_input_data = []\n",
    "\n",
    "encoder_max_seq_length = 0\n",
    "decoder_max_seq_length = 0\n",
    "\n",
    "for input_words, target_words in zip(input_texts, target_texts):\n",
    "    encoder_input_wids = []\n",
    "    for w in input_words:\n",
    "        w2idx = 1\n",
    "        if w in input_word2idx:\n",
    "            w2idx = input_word2idx[w]\n",
    "        encoder_input_wids.append(w2idx)\n",
    "\n",
    "    encoder_input_data.append(encoder_input_wids)\n",
    "    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n",
    "    decoder_max_seq_length = max(len(target_words), decoder_max_seq_length)\n",
    "\n",
    "context = dict()\n",
    "context['num_encoder_tokens'] = num_encoder_tokens\n",
    "context['num_decoder_tokens'] = num_decoder_tokens\n",
    "context['encoder_max_seq_length'] = encoder_max_seq_length\n",
    "context['decoder_max_seq_length'] = decoder_max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:47.071175Z",
     "start_time": "2020-05-31T16:55:47.066375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(encoder_input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:47.584452Z",
     "start_time": "2020-05-31T16:55:47.573081Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom function to generate batches\n",
    "\n",
    "def generate_batch(input_data, output_text_data):\n",
    "    '''\n",
    "    \n",
    "    input: \n",
    "        - input_data:\n",
    "        - output_text_data:\n",
    "        \n",
    "    output:\n",
    "        - \n",
    "        - \n",
    "    '''\n",
    "    \n",
    "    num_batches = len(input_data) // BATCH_SIZE\n",
    "    while True:\n",
    "        for batchIdx in range(0, num_batches):\n",
    "            start = batchIdx * BATCH_SIZE\n",
    "            end = (batchIdx + 1) * BATCH_SIZE\n",
    "            encoder_input_data_batch = pad_sequences(input_data[start:end], encoder_max_seq_length)\n",
    "            decoder_target_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens))\n",
    "            decoder_input_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens))\n",
    "            for lineIdx, target_words in enumerate(output_text_data[start:end]):\n",
    "                for idx, w in enumerate(target_words):\n",
    "                    w2idx = 0\n",
    "                    if w in target_word2idx:\n",
    "                        w2idx = target_word2idx[w]\n",
    "                    decoder_input_data_batch[lineIdx, idx, w2idx] = 1\n",
    "                    if idx > 0:\n",
    "                        decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1\n",
    "            yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:48.817043Z",
     "start_time": "2020-05-31T16:55:48.394788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compiling and training\n",
    "\n",
    "encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "encoder_embedding = Embedding(input_dim=num_encoder_tokens, output_dim=HIDDEN_UNITS,\n",
    "                              input_length=encoder_max_seq_length, name='encoder_embedding')\n",
    "\n",
    "encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_embedding(encoder_inputs))\n",
    "encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_inputs')\n",
    "decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
    "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n",
    "                                                                 initial_state=encoder_states)\n",
    "decoder_dense = Dense(units=num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:55:51.726900Z",
     "start_time": "2020-05-31T16:55:51.716997Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras.Model Arguments <br>\n",
    "- **inputs**: The input(s) of the model: a `keras.Input` object or list of `keras.Input` objects. <br>\n",
    "- **outputs**: The output(s) of the model. <br>\n",
    "- **name**: String, the name of the model. (opt) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:56:24.414834Z",
     "start_time": "2020-05-31T16:56:24.299876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, 20, 100)      95100       encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None, 952)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 100), (None, 80400       encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 100),  421200      decoder_inputs[0][0]             \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 952)    96152       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 692,852\n",
      "Trainable params: 692,852\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, 20, 100)      95100       encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None, 952)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 100), (None, 80400       encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 100),  421200      decoder_inputs[0][0]             \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 952)    96152       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 692,852\n",
      "Trainable params: 692,852\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compiling\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "#Compiling\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T08:55:43.795718Z",
     "start_time": "2020-05-31T08:55:43.685212Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoder_input_data, target_texts, test_size=0.2, random_state=42)\n",
    "\n",
    "train_gen = generate_batch(X_train, y_train)\n",
    "test_gen = generate_batch(X_test, y_test)\n",
    "\n",
    "train_num_batches = len(X_train) // BATCH_SIZE\n",
    "test_num_batches = len(X_test) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T22:55:22.073264Z",
     "start_time": "2020-05-30T22:55:22.061533Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "                        monitor='loss', \n",
    "                        min_delta=0.001, \n",
    "                        patience=3, mode='min', \n",
    "                        verbose=1\n",
    "                        )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "                            monitor='val_loss', \n",
    "                            factor=0.1, \n",
    "                            patience=4, \n",
    "                            verbose=1, \n",
    "                            min_delta=1e-4\n",
    "                            ) \n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "                            'model_best_weights.h5', #name of the document where the checkpoints will be saved\n",
    "                            monitor='loss', \n",
    "                            verbose=1, \n",
    "                            save_best_only=True, \n",
    "                            mode='min', \n",
    "                            period=1\n",
    "                            )\n",
    "\n",
    "\n",
    "my_callbacks = [early_stop,reduce_lr, checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T23:02:07.509236Z",
     "start_time": "2020-05-30T23:02:07.499368Z"
    }
   },
   "source": [
    "To train my model with the established vocabulary of 20k words and 500 epochs; and starting with 40k lines of my ds it would take an estimate of 17 days to train in my local machine.\n",
    "\n",
    "Epoch 1/500\n",
    "  8/312 [..............................] - ETA: 53:45 - loss: 9.0315\n",
    "  \n",
    " Using a VM the same model with the same parameters takes an estimate of 5 days.\n",
    " \n",
    " Epoch 1/500\n",
    "249/249 [==============================] - 923s 4s/step - loss: 6.7226 - val_loss: 6.4012\n",
    "\n",
    "To avoid unnecessary training I am using the callback attribute with `Earlystop` which will automatically stop the training once it has stopped improving, this means that it might take less time. We will see, today is 31.May.2020 01:19-\n",
    "\n",
    "-- **`40k lines of training is insufficient to have a properly trained model`**\n",
    "\n",
    "At the same time, given that it takes days to train, to avoid any technical issues I am using the `ModelCheckpoint` function which saves a copy of the model, in this case it is monitoring the 'loss', which on second though might not be the correct one and it should be monitoring the 'val_loss', but the main thing is that it makes a \"Security Copy\" of the model so if the Server of the VM were to disconnect or the Kernel were to die I'd have a least part of the model saved.\n",
    "\n",
    "Because we are working with NLG the training has to be very extense. That's why I'm creating different models, which might not be completed for due date but will be useful to get a general idea and even continue training that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T22:03:11.074186Z",
     "start_time": "2020-05-30T22:03:11.062999Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T22:52:02.691316Z",
     "start_time": "2020-05-30T22:52:02.685554Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_tot_500e = model.fit_generator(generator=train_gen,\n",
    "#                     steps_per_epoch=train_num_batches,\n",
    "#                     epochs=500, #NUM_EPOCHS,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=test_gen,\n",
    "#                     validation_steps=test_num_batches,\n",
    "#                     callbacks = my_callbacks\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T22:53:46.630452Z",
     "start_time": "2020-05-30T22:53:46.624981Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save(\"models/model_e_50k__lines_20kvocab.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:09:23.733193Z",
     "start_time": "2020-05-31T09:09:21.267197Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "#model = load_model('model_55e_lines_20kvocab.h5')# Not trained enough\n",
    "#model = load_model('model_79e_5klines_1kvocab.h5')# Not trained enough\n",
    "#model = load_model('model_All[600](vocab10k)_100epochs.h5')# Not trained enough\n",
    "#model = load_model(\"model_best_weights.h5\")\n",
    "\n",
    "model = load_model(\"model_35e_40klines_20kvocab.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:09:29.688163Z",
     "start_time": "2020-05-31T09:09:29.682441Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, 20, 100)      2000200     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None, 20001)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 100), (None, 80400       encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 100),  8040800     decoder_inputs[0][0]             \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 20001)  2020101     decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 12,141,501\n",
      "Trainable params: 12,141,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T08:53:54.599759Z",
     "start_time": "2020-05-31T08:53:54.580096Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plot_train_vs_test (model):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    \"\"\"\n",
    "    **************************************************************\n",
    "    \n",
    "    Visualiza en forma de grÃ¡fico las curvas del accuracy y del loss\n",
    "    entre el train y el test.\n",
    "\n",
    "    ***************************************************************\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (8, 6) \n",
    "    \n",
    "    plt.figure(0)  \n",
    "    plt.plot(model.history['acc'],'r')  \n",
    "    plt.plot(model.history['val_acc'],'g')  \n",
    "    plt.xticks(np.arange(0, epochs, 2.0))   \n",
    "    plt.xlabel(\"Num of Epochs\")  \n",
    "    plt.ylabel(\"Accuracy\")  \n",
    "    plt.title(\"Training Accuracy vs Validation Accuracy\")  \n",
    "    plt.legend(['train','validation'])\n",
    "\n",
    "    plt.figure(1)  \n",
    "    plt.plot(model.history['loss'],'r')  \n",
    "    plt.plot(model.history['val_loss'],'g')  \n",
    "    plt.xticks(np.arange(0, epochs, 2.0))   \n",
    "    plt.xlabel(\"Num of Epochs\")  \n",
    "    plt.ylabel(\"Loss\")  \n",
    "    plt.title(\"Training Loss vs Validation Loss\")  \n",
    "    plt.legend(['train','validation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T08:55:54.229416Z",
     "start_time": "2020-05-31T08:55:54.177698Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_vs_test (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:09:34.242726Z",
     "start_time": "2020-05-31T09:09:34.147264Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T09:51:36.070585Z",
     "start_time": "2020-05-31T09:51:34.570383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "njlkvlakef\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'homophobes origen origen testified chances mir furry tipping leek leek teased donaldson featherweight disgusting devalued job teach pulling hawkeye rub'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = input()\n",
    "input_seq = []\n",
    "input_wids = []\n",
    "max_encoder_seq_length = 20\n",
    "max_decoder_seq_length = 20\n",
    "\n",
    "for word in nltk.word_tokenize(input_text.lower()):\n",
    "    idx = 1\n",
    "    if word in input_word2idx:\n",
    "        idx = input_word2idx[word]\n",
    "    input_wids.append(idx)\n",
    "    \n",
    "input_seq.append(input_wids)\n",
    "input_seq = pad_sequences(input_seq, max_encoder_seq_length)\n",
    "states_value = encoder_model.predict(input_seq)\n",
    "target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "target_seq[0, 0, target_word2idx['START']] = 1\n",
    "target_text = ''\n",
    "target_text_len = 0\n",
    "terminated = False\n",
    "\n",
    "while not terminated:\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "    sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
    "    sample_word = target_idx2word[sample_token_idx]\n",
    "    target_text_len += 1\n",
    "\n",
    "    if sample_word != 'START' and sample_word != 'END':\n",
    "        target_text += ' ' + sample_word\n",
    "\n",
    "    if sample_word == 'END' or target_text_len >= max_decoder_seq_length:\n",
    "        terminated = True\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sample_token_idx] = 1\n",
    "\n",
    "    states_value = [h, c]\n",
    "    \n",
    "\n",
    "target_text.strip().replace('UNK', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T08:56:03.232469Z",
     "start_time": "2020-05-31T08:56:03.208404Z"
    }
   },
   "outputs": [],
   "source": [
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
