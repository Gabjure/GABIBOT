{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:20:26.387478Z",
     "start_time": "2020-05-28T18:20:18.730446Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Input, Embedding\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:50:43.035960Z",
     "start_time": "2020-05-28T18:50:42.327672Z"
    }
   },
   "outputs": [],
   "source": [
    "# set default parameters\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 100\n",
    "HIDDEN_UNITS = 100#256\n",
    "MAX_INPUT_SEQ_LENGTH = 20\n",
    "MAX_TARGET_SEQ_LENGTH = 20\n",
    "MAX_VOCAB_SIZE = 100\n",
    "\n",
    "input_counter = Counter()\n",
    "target_counter = Counter()\n",
    "\n",
    "# read the data\n",
    "\n",
    "df = pd.read_csv('SARC_DS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:50:43.598199Z",
     "start_time": "2020-05-28T18:50:43.581953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answer_1</th>\n",
       "      <th>Answer_2</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've been searching for the answer for this fo...</td>\n",
       "      <td>Religion must have the answer</td>\n",
       "      <td>It's obviously tracks from a giant water tract...</td>\n",
       "      <td>I've been searching for the answer for this fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
       "      <td>Wow...he smoked pot...oh lord hes such a horri...</td>\n",
       "      <td>Wow, his girlfriend is uhm... Ah fuck it, he's...</td>\n",
       "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Utah wants to create a database to track the i...</td>\n",
       "      <td>I think the government should track every morm...</td>\n",
       "      <td>Another idea from the party that wants to get ...</td>\n",
       "      <td>Utah wants to create a database to track the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Six Million Dead Jews of World War ONE!</td>\n",
       "      <td>Oh right, *both* wars were just jewish conspir...</td>\n",
       "      <td>i know this seems strange but, what if he was ...</td>\n",
       "      <td>The Six Million Dead Jews of World War ONE! Oh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WSJ begins the Jeb Bush campaign for 2016</td>\n",
       "      <td>Good luck with that.</td>\n",
       "      <td>time to get that shack in montana.</td>\n",
       "      <td>WSJ begins the Jeb Bush campaign for 2016 Good...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  I've been searching for the answer for this fo...   \n",
       "1  Michael Phelps Apologizes For \"Regrettable\" Be...   \n",
       "2  Utah wants to create a database to track the i...   \n",
       "3        The Six Million Dead Jews of World War ONE!   \n",
       "4          WSJ begins the Jeb Bush campaign for 2016   \n",
       "\n",
       "                                            Answer_1  \\\n",
       "0                      Religion must have the answer   \n",
       "1  Wow...he smoked pot...oh lord hes such a horri...   \n",
       "2  I think the government should track every morm...   \n",
       "3  Oh right, *both* wars were just jewish conspir...   \n",
       "4                               Good luck with that.   \n",
       "\n",
       "                                            Answer_2  \\\n",
       "0  It's obviously tracks from a giant water tract...   \n",
       "1  Wow, his girlfriend is uhm... Ah fuck it, he's...   \n",
       "2  Another idea from the party that wants to get ...   \n",
       "3  i know this seems strange but, what if he was ...   \n",
       "4                 time to get that shack in montana.   \n",
       "\n",
       "                                                 all  \n",
       "0  I've been searching for the answer for this fo...  \n",
       "1  Michael Phelps Apologizes For \"Regrettable\" Be...  \n",
       "2  Utah wants to create a database to track the i...  \n",
       "3  The Six Million Dead Jews of World War ONE! Oh...  \n",
       "4  WSJ begins the Jeb Bush campaign for 2016 Good...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:50:54.802562Z",
     "start_time": "2020-05-28T18:50:54.794841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Questions', 'Answer_1', 'Answer_2', 'all'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:51:42.623223Z",
     "start_time": "2020-05-28T18:51:42.521770Z"
    }
   },
   "outputs": [],
   "source": [
    "df['QandA'] = df['all']+ ' '+ df['Answer_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:51:44.986353Z",
     "start_time": "2020-05-28T18:51:44.882697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 128540 entries, 0 to 128539\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   Questions  128540 non-null  object\n",
      " 1   Answer_1   128540 non-null  object\n",
      " 2   Answer_2   128540 non-null  object\n",
      " 3   all        128540 non-null  object\n",
      " 4   QandA      128540 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:54:51.034721Z",
     "start_time": "2020-05-28T18:54:50.991420Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df.drop('all', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:02:05.086398Z",
     "start_time": "2020-05-28T19:02:05.082307Z"
    }
   },
   "outputs": [],
   "source": [
    "line = df.QandA\n",
    "input_texts = []\n",
    "target_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:02:06.064549Z",
     "start_time": "2020-05-28T19:02:06.057629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128540"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:06:13.999527Z",
     "start_time": "2020-05-28T19:04:32.435378Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_words = []\n",
    "\n",
    "for line in line:\n",
    "\n",
    "    next_words = [w.lower() for w in nltk.word_tokenize(line) if w.isalpha()]\n",
    "    #next_words = nltk.pos_tag(next_words)\n",
    "\n",
    "    if len(next_words) > MAX_TARGET_SEQ_LENGTH:\n",
    "        next_words = next_words[0:MAX_TARGET_SEQ_LENGTH]\n",
    "\n",
    "    if len(prev_words) > 0:\n",
    "        input_texts.append(prev_words)\n",
    "        for w in prev_words:\n",
    "            input_counter[w] += 1\n",
    "        target_words = next_words[:]\n",
    "        target_words.insert(0, 'START')\n",
    "        target_words.append('END')\n",
    "        for w in target_words:\n",
    "            target_counter[w] += 1\n",
    "        target_texts.append(target_words)\n",
    "\n",
    "    prev_words = next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:12:29.609650Z",
     "start_time": "2020-05-28T19:12:27.558996Z"
    }
   },
   "outputs": [],
   "source": [
    "# encode the data\n",
    "input_word2idx = dict()\n",
    "for idx, word in enumerate(input_counter.most_common(MAX_VOCAB_SIZE)):\n",
    "    input_word2idx[word[0]] = idx + 2\n",
    "    \n",
    "target_word2idx = dict()\n",
    "for idx, word in enumerate(target_counter.most_common(MAX_VOCAB_SIZE)):\n",
    "    target_word2idx[word[0]] = idx + 1\n",
    "\n",
    "input_word2idx['PAD'] = 0\n",
    "input_word2idx['UNK'] = 1\n",
    "target_word2idx['UNK'] = 0\n",
    "\n",
    "input_idx2word = dict([(idx, word) for word, idx in input_word2idx.items()])\n",
    "target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
    "\n",
    "num_encoder_tokens = len(input_idx2word)\n",
    "num_decoder_tokens = len(target_idx2word)\n",
    "\n",
    "\n",
    "encoder_input_data = []\n",
    "\n",
    "encoder_max_seq_length = 0\n",
    "decoder_max_seq_length = 0\n",
    "\n",
    "\n",
    "\n",
    "for input_words, target_words in zip(input_texts, target_texts):\n",
    "    \n",
    "    encoder_input_wids = []\n",
    "    \n",
    "    for w in input_words:\n",
    "        w2idx = 1\n",
    "        if w in input_word2idx:\n",
    "            w2idx = input_word2idx[w]\n",
    "        encoder_input_wids.append(w2idx)\n",
    "\n",
    "    encoder_input_data.append(encoder_input_wids)\n",
    "    \n",
    "    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n",
    "    decoder_max_seq_length = max(len(target_words), decoder_max_seq_length)\n",
    "\n",
    "context = dict()\n",
    "\n",
    "context['num_encoder_tokens'] = num_encoder_tokens\n",
    "context['num_decoder_tokens'] = num_decoder_tokens\n",
    "\n",
    "context['encoder_max_seq_length'] = encoder_max_seq_length\n",
    "context['decoder_max_seq_length'] = decoder_max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:12:31.337964Z",
     "start_time": "2020-05-28T19:12:31.327041Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom function to generate batches\n",
    "\n",
    "def generate_batch(input_data, output_text_data):\n",
    "    num_batches = len(input_data) // BATCH_SIZE\n",
    "    while True:\n",
    "        for batchIdx in range(0, num_batches):\n",
    "            start = batchIdx * BATCH_SIZE\n",
    "            end = (batchIdx + 1) * BATCH_SIZE\n",
    "            encoder_input_data_batch = pad_sequences(input_data[start:end], encoder_max_seq_length)\n",
    "            decoder_target_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens))\n",
    "            decoder_input_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens))\n",
    "            for lineIdx, target_words in enumerate(output_text_data[start:end]):\n",
    "                for idx, w in enumerate(target_words):\n",
    "                    w2idx = 0\n",
    "                    if w in target_word2idx:\n",
    "                        w2idx = target_word2idx[w]\n",
    "                    decoder_input_data_batch[lineIdx, idx, w2idx] = 1\n",
    "                    if idx > 0:\n",
    "                        decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1\n",
    "            yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:12:47.356566Z",
     "start_time": "2020-05-28T19:12:46.616893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Compiling and training\n",
    "\n",
    "encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "encoder_embedding = Embedding(input_dim=num_encoder_tokens, output_dim=HIDDEN_UNITS,\n",
    "                              input_length=encoder_max_seq_length, name='encoder_embedding')\n",
    "\n",
    "encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_embedding(encoder_inputs))\n",
    "encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_inputs')\n",
    "decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
    "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n",
    "                                                                 initial_state=encoder_states)\n",
    "decoder_dense = Dense(units=num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:12:52.140597Z",
     "start_time": "2020-05-28T19:12:52.017631Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoder_input_data, target_texts, test_size=0.2, random_state=42)\n",
    "\n",
    "train_gen = generate_batch(X_train, y_train)\n",
    "test_gen = generate_batch(X_test, y_test)\n",
    "\n",
    "train_num_batches = len(X_train) // BATCH_SIZE\n",
    "test_num_batches = len(X_test) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(generator=train_gen,\n",
    "#                     steps_per_epoch=train_num_batches,\n",
    "#                     epochs=NUM_EPOCHS,\n",
    "#                     verbose=1,\n",
    "#                      validation_data=test_gen,\n",
    "#                      validation_steps=test_num_batches,\n",
    "#                     ###callbacks = my_callbacks\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:32:02.456554Z",
     "start_time": "2020-05-28T19:32:01.362794Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('model_QnAcomb_100epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:35:07.991319Z",
     "start_time": "2020-05-28T19:35:07.842226Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:35:22.316964Z",
     "start_time": "2020-05-28T19:35:14.624353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are you doing?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'w elder camping camping between chairs ubi swear swear ma'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = input()\n",
    "input_seq = []\n",
    "input_wids = []\n",
    "max_encoder_seq_length = 20\n",
    "max_decoder_seq_length = 10\n",
    "\n",
    "for word in nltk.word_tokenize(input_text.lower()):\n",
    "    idx = 1\n",
    "    if word in input_word2idx:\n",
    "        idx = input_word2idx[word]\n",
    "    input_wids.append(idx)\n",
    "    \n",
    "input_seq.append(input_wids)\n",
    "input_seq = pad_sequences(input_seq, max_encoder_seq_length)\n",
    "states_value = encoder_model.predict(input_seq)\n",
    "target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "target_seq[0, 0, target_word2idx['START']] = 1\n",
    "target_text = ''\n",
    "target_text_len = 0\n",
    "terminated = False\n",
    "\n",
    "while not terminated:\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "    sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
    "    sample_word = target_idx2word[sample_token_idx]\n",
    "    target_text_len += 1\n",
    "\n",
    "    if sample_word != 'START' and sample_word != 'END':\n",
    "        target_text += ' ' + sample_word\n",
    "\n",
    "    if sample_word == 'END' or target_text_len >= max_decoder_seq_length:\n",
    "        terminated = True\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sample_token_idx] = 1\n",
    "\n",
    "    states_value = [h, c]\n",
    "    \n",
    "\n",
    "target_text.strip().replace('UNK', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:35:26.383891Z",
     "start_time": "2020-05-28T19:35:26.375937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, 20, 256)      2560512     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None, 10001)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 256), (None, 525312      encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  10504192    decoder_inputs[0][0]             \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 10001)  2570257     decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 16,160,273\n",
      "Trainable params: 16,160,273\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
