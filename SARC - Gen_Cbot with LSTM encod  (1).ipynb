{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:45:39.842345Z",
     "start_time": "2020-05-18T13:45:39.834286Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#basics\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#preprocessing\n",
    "\n",
    "\n",
    "#model bulding, validation and prediction\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation,\\\n",
    "        RepeatVector, TimeDistributed, ActivityRegularization\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:50:36.135418Z",
     "start_time": "2020-05-18T13:50:36.129742Z"
    }
   },
   "source": [
    "#### File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:50:36.135418Z",
     "start_time": "2020-05-18T13:50:36.129742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Questions = []\n",
    "# Answers = []\n",
    "    \n",
    "# with open(COMMENTS, 'r') as f:\n",
    "#     comments = json.load(f)\n",
    "    \n",
    "# with open(TRAIN_DATA, 'r') as f:\n",
    "#     reader = csv.reader(f, delimiter='|')\n",
    "#     for row in reader:\n",
    "#         ancestors = row[0].split(' ')\n",
    "#         responses = row[1].split(' ')\n",
    "#         Questions.append([comments[r]['text'] for r in ancestors])\n",
    "#         Answers.append([comments[r]['text'] for r in responses])\n",
    "\n",
    "# with open(TEST_DATA, 'r') as f:\n",
    "#     reader = csv.reader(f, delimiter='|')\n",
    "#     for row in reader:\n",
    "#         ancestors = row[0].split(' ')\n",
    "#         responses = row[1].split(' ')\n",
    "#         Questions.append([comments[r]['text'] for r in ancestors])\n",
    "#         Answers.append([comments[r]['text'] for r in responses])\n",
    "\n",
    "\n",
    "# QnAdata = pd.DataFrame(np.column_stack((Questions[:500], Answers[:500])),columns = [\"Questions\",\"Answer_1\", \"Answer_2\"])\n",
    "\n",
    "# QnAdata.head()\n",
    "\n",
    "# QnAdata['Questions'] = [' '.join(map(str, l)) for l in QnAdata['Questions']]\n",
    "\n",
    "# QnAdata[\"QnAcomb\"] = QnAdata[\"Questions\"]+\" \"+QnAdata[\"Answer_1\"]\n",
    "\n",
    "\n",
    "# print(QnAdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " QnAdata = pd.read_csv('SARC_DS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answer_1</th>\n",
       "      <th>Answer_2</th>\n",
       "      <th>QnAcomb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I've been searching for the answer for this fo...</td>\n",
       "      <td>Religion must have the answer</td>\n",
       "      <td>It's obviously tracks from a giant water tract...</td>\n",
       "      <td>I've been searching for the answer for this fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
       "      <td>Wow...he smoked pot...oh lord hes such a horri...</td>\n",
       "      <td>Wow, his girlfriend is uhm... Ah fuck it, he's...</td>\n",
       "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Utah wants to create a database to track the i...</td>\n",
       "      <td>I think the government should track every morm...</td>\n",
       "      <td>Another idea from the party that wants to get ...</td>\n",
       "      <td>Utah wants to create a database to track the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Six Million Dead Jews of World War ONE!</td>\n",
       "      <td>Oh right, *both* wars were just jewish conspir...</td>\n",
       "      <td>i know this seems strange but, what if he was ...</td>\n",
       "      <td>The Six Million Dead Jews of World War ONE! Oh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>WSJ begins the Jeb Bush campaign for 2016</td>\n",
       "      <td>Good luck with that.</td>\n",
       "      <td>time to get that shack in montana.</td>\n",
       "      <td>WSJ begins the Jeb Bush campaign for 2016 Good...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Questions  \\\n",
       "0           0  I've been searching for the answer for this fo...   \n",
       "1           1  Michael Phelps Apologizes For \"Regrettable\" Be...   \n",
       "2           2  Utah wants to create a database to track the i...   \n",
       "3           3        The Six Million Dead Jews of World War ONE!   \n",
       "4           4          WSJ begins the Jeb Bush campaign for 2016   \n",
       "\n",
       "                                            Answer_1  \\\n",
       "0                      Religion must have the answer   \n",
       "1  Wow...he smoked pot...oh lord hes such a horri...   \n",
       "2  I think the government should track every morm...   \n",
       "3  Oh right, *both* wars were just jewish conspir...   \n",
       "4                               Good luck with that.   \n",
       "\n",
       "                                            Answer_2  \\\n",
       "0  It's obviously tracks from a giant water tract...   \n",
       "1  Wow, his girlfriend is uhm... Ah fuck it, he's...   \n",
       "2  Another idea from the party that wants to get ...   \n",
       "3  i know this seems strange but, what if he was ...   \n",
       "4                 time to get that shack in montana.   \n",
       "\n",
       "                                             QnAcomb  \n",
       "0  I've been searching for the answer for this fo...  \n",
       "1  Michael Phelps Apologizes For \"Regrettable\" Be...  \n",
       "2  Utah wants to create a database to track the i...  \n",
       "3  The Six Million Dead Jews of World War ONE! Oh...  \n",
       "4  WSJ begins the Jeb Bush campaign for 2016 Good...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " QnAdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QnAdata = QnAdata.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answer_1</th>\n",
       "      <th>Answer_2</th>\n",
       "      <th>QnAcomb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've been searching for the answer for this fo...</td>\n",
       "      <td>Religion must have the answer</td>\n",
       "      <td>It's obviously tracks from a giant water tract...</td>\n",
       "      <td>I've been searching for the answer for this fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
       "      <td>Wow...he smoked pot...oh lord hes such a horri...</td>\n",
       "      <td>Wow, his girlfriend is uhm... Ah fuck it, he's...</td>\n",
       "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Utah wants to create a database to track the i...</td>\n",
       "      <td>I think the government should track every morm...</td>\n",
       "      <td>Another idea from the party that wants to get ...</td>\n",
       "      <td>Utah wants to create a database to track the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Six Million Dead Jews of World War ONE!</td>\n",
       "      <td>Oh right, *both* wars were just jewish conspir...</td>\n",
       "      <td>i know this seems strange but, what if he was ...</td>\n",
       "      <td>The Six Million Dead Jews of World War ONE! Oh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WSJ begins the Jeb Bush campaign for 2016</td>\n",
       "      <td>Good luck with that.</td>\n",
       "      <td>time to get that shack in montana.</td>\n",
       "      <td>WSJ begins the Jeb Bush campaign for 2016 Good...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  I've been searching for the answer for this fo...   \n",
       "1  Michael Phelps Apologizes For \"Regrettable\" Be...   \n",
       "2  Utah wants to create a database to track the i...   \n",
       "3        The Six Million Dead Jews of World War ONE!   \n",
       "4          WSJ begins the Jeb Bush campaign for 2016   \n",
       "\n",
       "                                            Answer_1  \\\n",
       "0                      Religion must have the answer   \n",
       "1  Wow...he smoked pot...oh lord hes such a horri...   \n",
       "2  I think the government should track every morm...   \n",
       "3  Oh right, *both* wars were just jewish conspir...   \n",
       "4                               Good luck with that.   \n",
       "\n",
       "                                            Answer_2  \\\n",
       "0  It's obviously tracks from a giant water tract...   \n",
       "1  Wow, his girlfriend is uhm... Ah fuck it, he's...   \n",
       "2  Another idea from the party that wants to get ...   \n",
       "3  i know this seems strange but, what if he was ...   \n",
       "4                 time to get that shack in montana.   \n",
       "\n",
       "                                             QnAcomb  \n",
       "0  I've been searching for the answer for this fo...  \n",
       "1  Michael Phelps Apologizes For \"Regrettable\" Be...  \n",
       "2  Utah wants to create a database to track the i...  \n",
       "3  The Six Million Dead Jews of World War ONE! Oh...  \n",
       "4  WSJ begins the Jeb Bush campaign for 2016 Good...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QnAdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:56:28.248607Z",
     "start_time": "2020-05-18T13:56:28.243332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vocabulary size: 144143\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter()\n",
    "\n",
    "for i in range(len(QnAdata)):\n",
    "    for word in nltk.word_tokenize(QnAdata.iloc[i][3]):\n",
    "        counter[word]+=1\n",
    "\n",
    "word2idx = {w:(i+1) for i,(w,_) in enumerate(counter.most_common())}        \n",
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "\n",
    "\n",
    "idx2word[0] = \"PAD\"\n",
    "\n",
    "vocab_size = len(word2idx)+1\n",
    "\n",
    "print(\"\\n\\nVocabulary size:\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:56:28.248607Z",
     "start_time": "2020-05-18T13:56:28.243332Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode(sentence, maxlen,vocab_size):\n",
    "    indices = np.zeros((maxlen, vocab_size))\n",
    "    for i, w in enumerate(nltk.word_tokenize(sentence)):\n",
    "        if i == maxlen: break\n",
    "        indices[i, word2idx[w]] = 1\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(indices, calc_argmax=True):\n",
    "    if calc_argmax:\n",
    "        indices = np.argmax(indices, axis=-1)\n",
    "    return ' '.join(idx2word[x] for x in indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used to vectorize the question and answers with the given maximum length for both questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = quesns_train[0]\n",
    "decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = quesns_train[0]\n",
    "decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions = QnAdata['Questions'][:100]\n",
    "Answers = QnAdata['Answer_1'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_maxlen = 10\n",
    "answer_maxlen = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.35 TiB for an array with shape (128541, 10, 144143) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-48564b4442e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mquestion_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mquesns_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_maxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion_maxlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-48564b4442e8>\u001b[0m in \u001b[0;36mcreate_questions\u001b[0;34m(question_maxlen, vocab_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_maxlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mquestion_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion_maxlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion_maxlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 1.35 TiB for an array with shape (128541, 10, 144143) and data type float64"
     ]
    }
   ],
   "source": [
    "##ORIGINAL\n",
    "# def create_questions(question_maxlen,vocab_size):\n",
    "#     question_idx = np.zeros(shape=(len(Questions),question_maxlen,vocab_size))\n",
    "    \n",
    "#     for q in range(len(Questions)):\n",
    "#         question = encode(Questions[q],question_maxlen,vocab_size)\n",
    "\n",
    "#         question_idx[i] = question \n",
    "#     return question_idx\n",
    "\n",
    "# quesns_train = create_questions(question_maxlen=question_maxlen,vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "º###ERROR PORQUE ALGUNAS RESPUESTAS SON NÚMEROS\n",
    "\n",
    "def create_questions(question_maxlen,vocab_size):\n",
    "    question_idx = np.zeros(shape=(len(Questions),question_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Questions)):\n",
    "        if type(q) == str:\n",
    "            question_idx[i] = encode(Questions[q],question_maxlen,vocab_size)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return question_idx\n",
    "\n",
    "quesns_train = create_questions(question_maxlen=question_maxlen,vocab_size=vocab_size)\n",
    "\n",
    "def create_answers(answer_maxlen,vocab_size):\n",
    "    answer_idx = np.zeros(shape=(len(Answers),answer_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Answers)):\n",
    "        if type(q) == str:\n",
    "            answer_idx[i] = encode(Answers[q],answer_maxlen,vocab_size)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return answer_idx\n",
    "\n",
    "answs_train = create_answers(answer_maxlen=answer_maxlen,vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,Dropout,Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import RepeatVector,TimeDistributed,ActivityRegularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 144143)        0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               73867264  \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 20, 144143)        18594447  \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 20, 144143)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, 144143)        0         \n",
      "=================================================================\n",
      "Total params: 92,461,711\n",
      "Trainable params: 92,461,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "\n",
    "question_layer = Input(shape=(question_maxlen,vocab_size))\n",
    "\n",
    "encoder_rnn = LSTM(n_hidden,dropout=0.2,recurrent_dropout=0.2)(question_layer)\n",
    "\n",
    "repeat_encode = RepeatVector(answer_maxlen)(encoder_rnn)\n",
    "\n",
    "dense_layer = TimeDistributed(Dense(vocab_size))(repeat_encode)\n",
    "\n",
    "regularized_layer = ActivityRegularization(l2=1)(dense_layer)\n",
    "\n",
    "softmax_layer = Activation('softmax')(regularized_layer)\n",
    "\n",
    "model = Model([question_layer],[softmax_layer])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Readers encouraged to try this\n",
    "encoder_rnn = Bidirectional(LSTM(n_hidden,dropout=0.2,recurrent_dropout=0.2),merge_mode='concat')(question_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "print(decode(quesns_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "quesns_train_2 = quesns_train.astype('float32')\n",
    "answs_train_2 = answs_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4417 samples, validate on 233 samples\n",
      "Epoch 1/1\n",
      "4417/4417 [==============================] - 534s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f5a3020c9d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(quesns_train_2, answs_train_2,batch_size=32,epochs=1,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(quesns_train_2, answs_train_2,batch_size=32,epochs=30,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(quesns_train_2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_pred = model.predict(quesns_train_2[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "print (decode(ans_pred[0]))\n",
    "print (decode(ans_pred[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REVISAR .fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
